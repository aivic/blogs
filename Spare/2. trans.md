## Introduction
In the previous [guide](), you were introduced to the SciPy linear algebra module. In this guide, you will learn about how SciPy is useful in conducting statistical analysis. 

By the end of this guide you'll be able to learn the following topics:


1. Working with distributions 
2. Analyzing one and two samples 
3. Kernel density estimation

## The Baseline
Throughout this guide, we will be using the following libraries:


```python
import numpy as np
import scipy as sp
from scipy import stats
```

## Working with Distributions
Distribution can either be continuous or discrete. In SciPy there are methods available for 98 continuous distributions and 14 discrete distributions. You can find these names and count using the following code:


```python
# List of continuous distributions
continuous_dist = [d for d in dir(stats) if isinstance(getattr(stats, d), stats.rv_continuous)]
continuous_dist

# Output:
# ['alpha',
#  'anglit',
#  'arcsine',
#  'argus',
#  'beta',
#  'betaprime',
#  'bradford',
#  'burr',
#  'burr12',
#  'cauchy',
#  'chi',
#  'chi2',
#  'cosine',
#  .
#  .
#  .
#  't',
#  'trapz',
#  'triang',
#  'truncexpon',
#  'truncnorm',
#  'tukeylambda',
#  'uniform',
#  'vonmises',
#  'vonmises_line',
#  'wald',
#  'weibull_max',
#  'weibull_min',
#  'wrapcauchy'] 

# Total number of continuous distributions
len(continuous_dist) # 98

# List of discrete distributions
discrete_dist = [d for d in dir(stats) if isinstance(getattr(stats, d), stats.rv_discrete)]
discrete_dist

# Output:
# ['bernoulli',
#  'binom',
#  'boltzmann',
#  'dlaplace',
#  'geom',
#  'hypergeom',
#  'logser',
#  'nbinom',
#  'planck',
#  'poisson',
#  'randint',
#  'skellam',
#  'yulesimon',
#  'zipf']

# Total number of discrete distributions
len(discrete_dist) # 14
```

Now, that we know what all distributions are currently supported by SciPy stats module, let us implement some basic distribution operations as shown:


```python
# ============================================================
# We can pass a vector to compute cdf or pdf at various points
# ============================================================
stats.norm.cdf(np.array([5, 8, 7]))

# Output:
# array([0.99999971, 1.        , 1.        ])

stats.norm.pdf(np.array([-1, 0, 1]))

# Output:
# array([0.24197072, 0.39894228, 0.24197072])

# Inference:
# The above results suggest that basic methods like pdf and cdf
# supports vectorization.

# ==============================================
# Computing mean, variance and standard deviance
# ==============================================
stats.norm.mean(), stats.norm.var(), stats.norm.std()

# Output:
# (0.0, 1.0, 1.0)

stats.norm.stats(moments="mv")

# Output:
# (array(0.), array(1.))

# ==============================================================
# To find the median of a distribution, we can use percent point
# function (ppf) which is actually opposite of cdf
# ==============================================================
stats.norm.ppf(0.9)

# Output:
# 1.2815515655446004

# ============================================================
# To generate the sequence of random variates, you can utilize
# the size argument in the rvs method
# ============================================================
stats.norm.rvs(size=5)

# Output: (random)
# array([ 1.12143471,  1.13711089,  0.70657281, -0.73941283,  0.09078616])

# To achieve same numbers everytime, you can either set random_state
# inside the rvs method or rely on numpy.random.seed() method

np.random.seed(42) # Alternative to random_state argument

stats.norm.rvs(size=5, random_state=42)

# Output:
# array([ 0.49671415, -0.1382643 ,  0.64768854,  1.52302986, -0.23415337])
```

All continuous distributions take `loc` and `scale` as keyword arguments to adjust the location and scale of the distribution. For instance, for the standard normal distribution the location is the mean and the scale is the standard deviation.


```python
# ====================
# Shifting and Scaling
# ====================
stats.norm.stats(loc=2, scale=3, moments="mv")

# Output:
# (array(2.), array(9.))

stats.uniform.cdf([0, 1, 5, 2, 4, 5], loc=1, scale=4)

# Output:
# array([0.  , 0.  , 1.  , 0.25, 0.75, 1.  ])

stats.norm.rvs(5, size=7) # Here 5 is passed to loc

# Output:
# array([4.51287462, 4.40760608, 4.13600923, 5.04852163, 4.16904988,
#        5.27045683, 4.94976189])
```

Passing the arguments `loc` and `scale` (in case of distribution like gamma), again and again can become quite cumbersome. Therefore, there's a way to avoid this by freezing the distribution. This is shown in the code below:


```python
# Freezing the distribution
rv = stats.gamma(1, scale=2.)

# Here by passing the results to rv, you no longer have to 
# include the scale or the shape parameters anymore.
```

